{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T08:02:03.676328Z",
     "start_time": "2024-04-27T08:02:03.673771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"./models/self_model_multi\"\n",
    "THRESHOLD = 0.9\n",
    "\n",
    "LABELS = ['greeting', 'how are you', 'unknown']\n",
    "LABEL_MAP = {i: LABELS[i] for i in range(0, len(LABELS))}\n",
    "ID_MAP = {value: key for key, value in LABEL_MAP.items()}"
   ],
   "id": "b22aa8f3aec289de",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T08:02:08.102085Z",
     "start_time": "2024-04-27T08:02:03.677333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "MODEL_FILE = \"model.bin\"\n",
    "CONFIG_FILE = \"config.json\"\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.config = config\n",
    "        self.bert = BertModel.from_pretrained('ai-forever/sbert_large_nlu_ru', config=config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        probabilities = self.sigmoid(logits)\n",
    "        return probabilities\n",
    "    def save_pretrained(self, save_directory):\n",
    "        if not os.path.exists(save_directory):\n",
    "            os.makedirs(save_directory)\n",
    "\n",
    "        config_path = os.path.join(save_directory, CONFIG_FILE)\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(self.config.__dict__, f)\n",
    "\n",
    "        model_path = os.path.join(save_directory, MODEL_FILE)\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_path, *model_args, **kwargs):\n",
    "        config = BertConfig.from_pretrained(pretrained_model_path)\n",
    "        model = cls(config, *model_args, **kwargs)\n",
    "        model.load_state_dict(torch.load(os.path.join(pretrained_model_path, MODEL_FILE)))\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "model = BertClassifier.from_pretrained(MODEL_NAME)\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ],
   "id": "f66661f63d1cf822",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T08:02:08.231570Z",
     "start_time": "2024-04-27T08:02:08.102085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "id": "788a70d10a8c5a52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T08:02:08.474334Z",
     "start_time": "2024-04-27T08:02:08.231570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATASET_NAME = \"./datasets/ru-plus.csv\"\n",
    "\n",
    "df = pd.read_csv(DATASET_NAME, delimiter=\"|\")\n",
    "df.columns = ['text', 'label']\n",
    "df['label'] = df['label'].astype(int)\n",
    "df_label_0 = df[df[\"label\"] == 0]\n",
    "df_label_1 = df[df[\"label\"] == 1]\n",
    "multi_class = []\n",
    "for i in range(50):\n",
    "    row_0 = df_label_0.sample(n=1, random_state=np.random.RandomState())\n",
    "    row_1 = df_label_1.sample(n=1, random_state=np.random.RandomState())\n",
    "    text = f\"{row_0['text'].values[0]}, {row_1['text'].values[0].lower()}\"\n",
    "    multi_class.append({'text': text, 'label': 3})\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(multi_class)], ignore_index=True)\n",
    "df['label'] = df['label'].map({0: [1, 0], 1: [0, 1], 2: [0, 0], 3: [1, 1]})\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()"
   ],
   "id": "d42c64ea602dd61",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T08:02:08.477846Z",
     "start_time": "2024-04-27T08:02:08.474841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_text(model, tokenizer, text, threshold):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokenized_value = tokenizer(text,  padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
    "        output_value = model(tokenized_value['input_ids'].to(device), attention_mask=tokenized_value['attention_mask'].to(device))\n",
    "        predictions = output_value[0].cpu().numpy()\n",
    "        output_value = predictions > threshold\n",
    "        return output_value.astype(int).tolist(), predictions.tolist()"
   ],
   "id": "c8640513f3bca7b3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T08:02:14.683360Z",
     "start_time": "2024-04-27T08:02:08.478351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ],
   "id": "68d401266ced3e1a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T08:02:18.336531Z",
     "start_time": "2024-04-27T08:02:14.683360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "results = []\n",
    "for test_text, test_label in zip(texts, labels):\n",
    "    inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=128)\n",
    "    outputs, predictions = classify_text(model, tokenizer, test_text, THRESHOLD)\n",
    "    results.append(outputs)\n",
    "    if outputs != test_label:\n",
    "        counter += 1\n",
    "        print(f\"Текст: {test_text}\")\n",
    "        print(f\"Предсказано: {outputs}, Значение: {test_label}, Результат: {predictions}\")\n",
    "        print()\n",
    "print(f\"Всего ошибочно: {counter}\")\n",
    "\n",
    "print(', '.join(f\"{key}: {value:.4f}\" for key, value in metric.compute(predictions=np.array(results).reshape(-1), references=np.array(labels).reshape(-1)).items()))"
   ],
   "id": "b7814b4e7affd52a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего ошибочно: 0\n",
      "accuracy: 1.0000, f1: 1.0000, precision: 1.0000, recall: 1.0000\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
